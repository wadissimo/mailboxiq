{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud auth application-default set-quota-project sunny-lightning-392907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4db5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b721e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "import vertexai\n",
    "\n",
    "def interview(project_id, location, temperature: float = .2):\n",
    "    \"\"\"Ideation example with a Large Language Model\"\"\"\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    # TODO developer - override these parameters as needed:\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_output_tokens\": 256,\n",
    "        \"top_p\": .8,\n",
    "        \"top_k\": 40,\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        'Give me ten interview questions for the role of program manager.',\n",
    "        **parameters,\n",
    "    )\n",
    "    print(f\"Response from Model: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc2ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview('sunny-lightning-392907', 'us-central1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2c345",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc511d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sr.Microphone(device_index=0) as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)\n",
    "user_input = r.recognize_google(audio)\n",
    "user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "You are an assistant who helps users understand more about our application.\n",
    "Users will ask you questions and you will answer them given them below context:\n",
    "\n",
    "About the application:\n",
    "Our application is an outlook plugin which helps users to analyze and write their emails more efficiently.\n",
    "\n",
    "User question:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875f698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "import vertexai\n",
    "\n",
    "def send_user_input(project_id, location, question, temperature: float = .2):\n",
    "    vertexai.init(project=project_id, location=location)\n",
    "    \n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_output_tokens\": 256,\n",
    "        \"top_p\": .8,\n",
    "        \"top_k\": 40,\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    response = model.predict(\n",
    "        context + question ,\n",
    "        **parameters,\n",
    "    )\n",
    "    print(f\"Response from Model: {response.text}\")\n",
    "    return response.text\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf333d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = send_user_input('sunny-lightning-392907', 'us-central1', user_input)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gTTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "  \n",
    "# This module is imported so that we can \n",
    "# play the converted audio\n",
    "import os\n",
    "  \n",
    "# The text that you want to convert to audio\n",
    "mytext = response\n",
    "  \n",
    "# Language in which you want to convert\n",
    "language = 'en'\n",
    "  \n",
    "# Passing the text and language to the engine, \n",
    "# here we have marked slow=False. Which tells \n",
    "# the module that the converted audio should \n",
    "# have a high speed\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "  \n",
    "# Saving the converted audio in a mp3 file named\n",
    "# welcome \n",
    "myobj.save(\"welcome.mp3\")\n",
    "  \n",
    "# Playing the converted file\n",
    "#os.system(\"start text.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308f0447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffpyplayer in c:\\users\\vadim\\anaconda3\\lib\\site-packages (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffpyplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572c8c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\vadim\\anaconda3\\lib\\site-packages (from opencv-python) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.0.76\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd80f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Using cached playsound-1.3.0-py3-none-any.whl\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65661547",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install pandas\n",
    "!pip install pygame\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
